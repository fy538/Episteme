# Django
DEBUG=True
SECRET_KEY=your-secret-key-here-change-in-production
DJANGO_SETTINGS_MODULE=config.settings.development
ALLOWED_HOSTS=localhost,127.0.0.1

# Database
DATABASE_URL=postgresql://episteme:episteme@db:5432/episteme

# Redis & Celery
REDIS_URL=redis://redis:6379/0
CELERY_BROKER_URL=redis://redis:6379/0
CELERY_RESULT_BACKEND=redis://redis:6379/0

# CORS (for frontend)
CORS_ALLOWED_ORIGINS=http://localhost:3000,http://127.0.0.1:3000

# Logging & Error Tracking (Sentry)
SENTRY_DSN=
SENTRY_ENVIRONMENT=development
SENTRY_TRACES_SAMPLE_RATE=0.1

# Frontend Sentry (Next.js)
NEXT_PUBLIC_SENTRY_DSN=
NEXT_PUBLIC_SENTRY_ENVIRONMENT=development
NEXT_PUBLIC_SENTRY_TRACES_SAMPLE_RATE=0.1

# AI/LLM Services (PydanticAI & ADK)
# OpenAI: https://platform.openai.com/api-keys
OPENAI_API_KEY=
# DeepSeek: https://platform.deepseek.com/ (Recommended for Reasoning/Extraction)
DEEPSEEK_API_KEY=
# Groq: https://console.groq.com/ (Recommended for Fast/Latent-sensitive tasks)
GROQ_API_KEY=
# Google: https://aistudio.google.com/ (For ADK and Large Context)
GOOGLE_API_KEY=
# Anthropic: https://console.anthropic.com/
ANTHROPIC_API_KEY=

# Model Selection (Solo Founder Mode)
# Reasoning: Signal analysis, summaries. Use DeepSeek or GPT-4o
AI_MODEL_REASONING=openai:gpt-4o-mini
# Fast: Title generation, quick classification. Use Groq/Llama or GPT-4o-mini
AI_MODEL_FAST=openai:gpt-4o-mini
# Extraction: Signal extraction. Use DeepSeek or GPT-4o
AI_MODEL_EXTRACTION=openai:gpt-4o-mini

# Optional: Logfire for LLM observability
EMBEDDING_BACKEND=postgresql
# Options: postgresql (default), pgvector (future), pinecone (legacy)

# Pinecone (optional - legacy support during migration)
# Get API key from: https://www.pinecone.io/
# PINECONE_API_KEY=
# PINECONE_ENVIRONMENT=us-east-1

# Optional: Logfire for LLM observability
# Get token from: https://logfire.pydantic.dev/
# LOGFIRE_TOKEN=
